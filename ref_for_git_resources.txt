# NeuralCascade
"blame chatgpt for the repo's title" ~ ChatGPT

# BTech Engineering Project Repository

## Overview

This repository documents my journey from fundamental matrix-based approaches to advanced transformer architectures in machine learning. It serves as a structured collection the work, covering key developments and experiments in deep learning.

## Project Scope

The repository is divided into multiple sections that encapsulate different stages of the project:

### 1. **Fundamental Approaches**

- Simple matrix-based methods.
- Multi-Layer Perceptrons (MLPs).
- Hierarchical deep learning architectures such as dilated causal convolutional networks (inspired by WaveNet).

### 2. **Recurrent Architectures**
- Implementation of Recurrent Neural Networks (RNNs) for sequence modeling.
- Long Short-Term Memory (LSTM) networks for capturing long-range dependencies.

### 3. **Advanced Architectures**

- Transformer implementation inspired by *Attention Is All You Need*.
- Multi-headed self-attention mechanisms.
- Scaling experiments with various hyperparameter settings.

## Fun Outputs :D

I have included a **Fun Outputs** folder to showcase interesting generative results!

### 1. **Human-like Name Generation**

Used different architectures (Matrix-based, MLP, and Dilated Causal Convolutional Network), to generate realistic human-like names.

### 2. **AI-Generated Lyrics (Taylor Swift Style)**

A model trained on Taylor Swift's song lyrics to generate similar-sounding lyrics in her style.

### 3. **AI-Generated Plays (Shakespearean Style)**

A model trained on William Shakespeareâ€™s plays to generate text that mimics his writing style.

Pretty cool huh!

## Future Work

- State-space models and MAMBA.
- CLIP model.
- Fine-tuning models on datasets.